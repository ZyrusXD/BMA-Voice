# core/keyword_utils.py (ฉบับเต็ม - แก้ไข SyntaxError)

import re
from pythainlp import word_tokenize
from pythainlp.corpus import thai_stopwords
from pythainlp.tokenize import Tokenizer # (Import ที่ถูกต้อง)

# --- 1. ส่วน Tokenizer (ที่คุณแก้ไข) ---
CUSTOM_BMA_WORDS = [
    'ไฟฟ้าดับ', 'ไฟดับ', 'น้ำท่วม', 'ท่อตัน', 'ทางเท้า', 'ฝาท่อ', 'น้ำเน่า',
    'สายไฟ', 'รถติด', 'ขยะ', 'กทม', 'BMA', 'บีเอ็มเอ', 'สะพานลอย',
    'จราจร', 'ฟุตบาท', 'โรงพยาบาล', 'สุขภาพ', 'สาธารณสุข',
    'ตำรวจ', 'ดับเพลิง', 'ความปลอดภัย', 'อุบัติเหตุ', 'อาชญากรรม',
    'โรงเรียน', 'การศึกษา', 'นักเรียน', 'ครู', 'ห้องสมุด',
    'ทุจริต', 'โกง', 'โปร่งใส', 'ตรวจสอบ', 'คลอง', 
]

# (Key Fix!) สร้าง Tokenizer พร้อม custom dictionary
_tokenizer = Tokenizer(custom_dict=CUSTOM_BMA_WORDS, engine='newmm') 

# โหลด Stopwords
STOP_WORDS = set(thai_stopwords())

# --- 2. ส่วน Sentiment (จากโค้ดของคุณ) ---
SENTIMENT_LEXICON = {
    # (คำบวก +1)
    "ดี": 1, "ดีมาก": 1, "เยี่ยม": 1, "เห็นด้วย": 1, "สนับสนุน": 1, "ชอบ": 1,
    "ยอดเยี่ยม": 1, "สะดวก": 1, "รวดเร็ว": 1, "สะอาด": 1, "ปลอดภัย": 1, "มีประโยชน์": 1, 
    "ประทับใจ": 1, "สวยงาม": 1, "พัฒนา": 1, "เรียบร้อย": 1, "ขอบคุณ": 1, "ชื่นชม": 1,
    "โปร่งใส": 1, "ตรวจสอบได้": 1, "เป็นธรรม": 1,
    
    # (คำลบ -1)
    "แย่": -1, "ห่วย": -1, "ช้า": -1, "ไม่เห็นด้วย": -1, "ปัญหา": -1, "น่าเบื่อ": -1,
    "ผิดหวัง": -1, "ไร้ประโยชน์": -1, "ไม่สะดวก": -1, "แพง": -1, "ยอดแย่": -1, "วิกฤต": -1,
    "เดือดร้อน": -1, "ห่วยแตก": -1, "แออัด": -1, "สกปรก": -1, "ร้อน": -1, "น่ากลัว": -1, 
    "ไม่ปลอดภัย": -1, "ลำบาก": -1, "ขยะเยอะ": -1, "เสียงดัง": -1, "มลพิษ": -1, "ชำรุด": -1, 
    "ไม่เหมาะสม": -1, "ไม่โปร่งใส": -1, "ทุจริต": -1, "โกง": -1, "ไม่พัฒนา": -1,
    "ไม่ดี": -1, "ไม่เหมาะ": -1, "ไม่คุ้ม": -1, "วุ่นวาย": -1, "น่ารำคาญ": -1,
    "บริการแย่": -1, "พูดไม่ดี": -1, "อันตราย": -1, "ไม่สะอาด": -1, "ฝุ่นเยอะ": -1, 
    "ถนนพัง": -1, "น้ำท่วม": -1, "ขยะล้น": -1, "ไม่แก้ปัญหา": -1, "ไม่รับฟัง": -1, 
    "ล่าช้า": -1, "เพิกเฉย": -1, "แย่มาก": -1, "อึดอัด": -1, "ล้มเหลว": -1, "เสียบ่อย": -1, "น้ำเน่า": -1, "กลิ่นเหม็น": -1,"กลิ่นเน่า": -1,
}

# --- 3. ส่วน Keyword Tagging (จากโค้ดของคุณ) ---
POLICY_KEYWORDS = set([
    # (ผมรวม CUSTOM_BMA_WORDS เข้าไปด้วย)
    "ไฟฟ้าดับ", "ไฟดับ", "น้ำท่วม", "น้ำเน่า", "ท่อตัน", "ทางเท้า", "ฝาท่อ",
    "สายไฟ", "รถติด", "ขยะ", "กทม", "BMA", "บีเอ็มเอ", "สะพานลอย",
    "จราจร", "ฟุตบาท", "โรงพยาบาล", "สุขภาพ", "สาธารณสุข",
    "ตำรวจ", "ดับเพลิง", "ความปลอดภัย", "อุบัติเหตุ", "อาชญากรรม",
    "โรงเรียน", "การศึกษา", "นักเรียน", "ครู", "ห้องสมุด",
    "ทุจริต", "โกง", "โปร่งใส", "ตรวจสอบ",
    "การจราจร", "ไฟแดง", "ถนน", "รถเมล์", "รถไฟฟ้า",
    "ความสะอาด", "คลอง", "สวนสาธารณะ", "มลพิษ", "ฝุ่นละออง",
    "เสียงดัง", "ท่อระบายน้ำ", "ต้นไม้", "ไฟส่องสว่าง", "สิ่งแวดล้อม",
    "โควิด", "วัคซีน", "สุขาภิบาล", "ไฟไหม้", "ฉุกเฉิน", "ชุมชน", "กีฬา",
    "เศรษฐกิจ", "งบประมาณ", "ตลาด", "ภาษี", "การพัฒนาเมือง", "การท่องเที่ยว",
    "นโยบาย", "กฎหมาย", "ระเบียบ", "การบริหารเมือง",
])

# --- 4. Mapping แท็ก (Tag) ไปยัง 9 ด้าน (Policy Aspect) ---
POLICY_MAPPING = {
    'เดินทางดี': ["การจราจร", "ไฟแดง", "ทางเท้า", "สะพาน", "ถนน", "รถเมล์", "รถไฟฟ้า", "รถจักรยาน", "ที่จอดรถ", "ระบบขนส่ง", "ทางด่วน", "รถตู้", "ขนส่งสาธารณะ", "รถติด", "ป้ายจราจร", "เลนจักรยาน", "แท็กซี่", "มอเตอร์ไซค์รับจ้าง", "ฟุตบาท", "สะพานลอย"],
    'ปลอดภัยดี': ["ปลอดภัย", "ความปลอดภัย", "ตำรวจ", "ดับเพลิง", "อุบัติเหตุ", "อาชญากรรม", "ยาเสพติด", "ไฟไหม้", "ฉุกเฉิน", "กู้ภัย", "ความปลอดภัยทางถนน", "สายด่วน", "ไม่ปลอดภัย", "อันตราย"],
    'โปร่งใสดี': ["โปร่งใส", "การตรวจสอบ", "ทุจริต", "โกง", "ไม่โปร่งใส", "ข้อบังคับ", "กฎระเบียบ"],
    'สิ่งแวดล้อมดี': ["ขยะ", "ความสะอาด", "คลอง", "สวนสาธารณะ", "พื้นที่สีเขียว", "มลพิษ", "ฝุ่นละออง", "เสียงดัง", "ขยะล้น", "ท่อระบายน้ำ", "มลพิษทางอากาศ", "ต้นไม้", "ไฟส่องสว่าง", "สิ่งแวดล้อม", "ควัน", "จัดการน้ำเสีย", "ไฟฟ้าดับ", "ไฟดับ", "ท่อตัน", "ฝาท่อ", "สายไฟ", "สกปรก", "ขยะเยอะ", "ถนนพัง", "ขยะล้น", "ไม่สะอาด", "ฝุ่นเยอะ"],
    'สุขภาพดี': ["โรงพยาบาล", "สุขภาพ", "สาธารณสุข", "โควิด", "วัคซีน", "สุขาภิบาล", "ตรวจสุขภาพ", "โรงพยาบาลสนาม", "น้ำท่วม"],
    'เรียนดี': ["โรงเรียน", "การศึกษา", "นักเรียน", "ครู", "มหาวิทยาลัย", "ทุนการศึกษา", "ห้องสมุด", "ศูนย์เด็กเล็ก", "การเรียนรู้"],
    'เศรษฐกิจดี': ["เศรษฐกิจ", "งบประมาณ", "การลงทุน", "โครงการสาธารณะ", "ธุรกิจ", "การค้า", "ตลาด", "อุตสาหกรรม", "ภาษี", "การพัฒนาเมือง", "รายได้", "แรงงาน", "การจ้างงาน", "ค่าครองชีพ", "การท่องเที่ยว", "กิจการ"],
    'สังคมดี': ["กิจกรรมเยาวชน", "สวัสดิการ", "ชุมชน", "กิจกรรมสาธารณะ", "พัฒนาชุมชน", "กีฬา", "ความเท่าเทียม", "สิทธิ", "เยาวชน", "การมีส่วนร่วม"],
    'บริหารจัดการดี': ["นโยบาย", "กฎหมาย", "ระเบียบ", "มาตรฐาน", "การบริหารเมือง", "การจัดการ", "แผนพัฒนา", "ประชาสัมพันธ์", "ผู้บริหาร", "รายงาน", "ข้อเสนอ", "การวางแผน", "นโยบายสาธารณะ", "ข้อคิดเห็น", "กทม", "BMA"],
}

KEYWORD_TO_POLICY_MAP = {}
for policy, keywords in POLICY_MAPPING.items():
    for keyword in keywords:
        KEYWORD_TO_POLICY_MAP[keyword] = policy
# --- (สิ้นสุดส่วน Mapping) ---


def extract_keywords_from_text(text: str) -> list[str]:
    """
    (อัปเกรด) ฟังก์ชันสำหรับ "ตรวจจับ" Keyword
    """
    if not text:
        return []
        
    # (แก้ไข) ลบ 'engine="newmm"' ออก
    tokens = set(_tokenizer.word_tokenize(text)) 
    detected_keywords = tokens.intersection(POLICY_KEYWORDS)
    
    final_keywords = []
    for token in detected_keywords:
        token_clean = token.strip().lower()
        if (
            len(token_clean) > 2 and       
            not token_clean.isnumeric() and  
            token_clean not in STOP_WORDS and 
            re.match(r'^[ก-๙a-zA-Z]+$', token_clean) 
        ):
            final_keywords.append(token_clean)
            
    return list(set(final_keywords))

def analyze_sentiment(comment: str) -> int:
    """
    วิเคราะห์ความรู้สึกจากข้อความ
    """
    if not comment:
        return 0
        
    # (แก้ไข) ลบ 'engine="newmm"' ออก
    tokens = _tokenizer.word_tokenize(comment)
    score = 0
    
    for token in tokens:
        if token in SENTIMENT_LEXICON:
            score += SENTIMENT_LEXICON[token]
            
    return score

def triage_policy_aspect(keywords: list) -> str:
    """
    (ใหม่!) วิเคราะห์ว่า Keyword ที่ได้มา ตกอยู่ใต้นโยบาย 9 ด้านใด
    """
    if not keywords:
        return 'ไม่ระบุ'
    
    for keyword in keywords:
        if keyword in KEYWORD_TO_POLICY_MAP:
            return KEYWORD_TO_POLICY_MAP[keyword] # (คืนค่าด้านแรกที่เจอ)
            
    return 'ไม่ระบุ'

# --- [แก้ไข!] ลบ '}' ที่เป็น Syntax Error ออกจากบรรทัดนี้ ---